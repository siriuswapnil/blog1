---
title: "#2 Basics of Probability for ML "
date: 2020-08-03T23:45:59+05:30
draft: false
categories: 
- machine learning
---
# Basics of Probability for Machine Learning

- Unlike classical programming, there are no black or white solutions available to machine learing problems. Hence, probability is an important component in the study of ML
- Statistical Model : This is a mathematical model, that embodies a set of statistical assumptions, concerning the generation of sample data. A statistical model generally represents the data generating process.
- Learning probability theory will serve as the theoretical background that will help us to make better choices during times of dilemma over techniques one can use for predictions.

# Probability Distributions in Data Science : 
* If we are able to understand if itâ€™s present any pattern in the data distribution, we can then tailor-made our Machine Learning models to best fit our case study.

## Types of Data : 
A dataset represents a sample of a population.
Datasets are composed of generally two types of data = Numerical and Categorical.

Numerical Data => 
1. Discrete - The type of data that can take only certain values.
2. Continue - It ccan take any real or fractional value.

For discrete random variables, we calculate *Probability Mass Functions*. It gives the probability that a variabl is equal to a certain value.

For continuous random variable, we have *Probability Density Functions*. They first need to be integrated over a given range.

### The most common probability distribution:  
1. Bernoulli
2. Binomial
3. Geometric
4. Poisson's ratio
6. Exponential

## Bernouli Doscription : 
